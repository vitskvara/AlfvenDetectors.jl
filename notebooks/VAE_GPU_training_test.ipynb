{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here lets try to get some data from the alfven modes and train a few autoencoders on them to see if they capture any structure in the latent layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using AlfvenDetectors\n",
    "using PyPlot\n",
    "using Flux\n",
    "using CuArrays  # for GPU runs\n",
    "using ValueHistories\n",
    "using BSON: @save, @load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are doing is unsupervised training on columns of the magnitude squared coherence time histograms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the data\n",
    "\n",
    "Use shot #10370 and #11960 and several coil couples. Select only some timeslices, normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = gethostname()\n",
    "if occursin(\"vit\", host)\n",
    "    datapath = \"/home/vit/vyzkum/alfven/cdb_data/original_data/\"\n",
    "else\n",
    "    datapath = \"/home/skvara/work/alfven/cdb_data/original_data/\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_msc_array(datapath, shot, coil, timelim = [1.0, 1.25])\n",
    "    _data = AlfvenDetectors.BaseAlfvenData(joinpath(datapath,\"$(shot).h5\"), [coil])\n",
    "    tinds = timelim[1] .<= _data.t .<= timelim[2]\n",
    "    return _data.msc[coil][:,tinds], _data.t[tinds], _data.f \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc, t, f = get_msc_array(datapath, 11096, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcolormesh(t,f,msc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function collect_msc(datapath, shot, coils)\n",
    "    datalist = map(x-> get_msc_array(datapath, shot, x), coils)\n",
    "    return hcat([x[1] for x in datalist]...), datalist[1][3]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_coils = [\n",
    "#    [10370, [12, 15, 17, 20]],\n",
    "    [10370, [12, 20]],\n",
    "#    [11096, [11, 8, 17, 20]]\n",
    "    [11096, [11, 8, 20]]\n",
    "]\n",
    "datalist = map(x->collect_msc(datapath, x[1], x[2]), shots_coils)\n",
    "data, f = hcat([x[1] for x in datalist]...), datalist[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcolormesh(1:size(data,2), f, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have the data, construct a VAE\n",
    "\n",
    "Larger dimension of middle layer is beneficial, but improvement from 10 to 20 is much alrger than from 20 to 200.\n",
    "\n",
    "Reconstruction works even with zdim = 2 although there are some artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N = size(data)\n",
    "# fortunately data is already normalized in the interval (0,1)\n",
    "zdim = 2\n",
    "small_model = AlfvenDetectors.VAE([M, 20, zdim*2], [zdim, 20, M])\n",
    "large_model = AlfvenDetectors.VAE([M, 200, zdim*2], [zdim, 200, M])\n",
    "small_train_history = MVHistory()\n",
    "large_train_history = MVHistory()\n",
    "batchsize = 64\n",
    "nepochs = 200\n",
    "cbit = 1\n",
    "# progress bars are broken in notebooks\n",
    "if occursin(\".jl\", @__FILE__) \n",
    "    verb = true\n",
    "else\n",
    "    verb = false\n",
    "end\n",
    "# VAE specific settings\n",
    "L = 1\n",
    "β = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Training small CPU model\"\n",
    "@time AlfvenDetectors.fit!(small_model, data, batchsize, 1;\n",
    "    β = β, L = L,\n",
    "    cbit = cbit, history = small_train_history, verb = verb)\n",
    "@time AlfvenDetectors.fit!(small_model, data, batchsize, nepochs-1;\n",
    "    β = β, L = L,\n",
    "    cbit = cbit, history = small_train_history, verb = verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a fast run saves about 20% of allocations, still more than 2x as many as compared to AE. Also, setting $\\beta$ to large values around 1 is detrimental to the reconstruction - however it is not detrimental to the clustering in latent space, as it still shows even when more weight is put on KL. Also, the generated samples look more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Training large CPU model\"\n",
    "@time AlfvenDetectors.fit!(large_model, data, batchsize, nepochs;\n",
    "    L = L, β = 1.0,\n",
    "    cbit = cbit, history = large_train_history, verb = verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "plot(get(small_train_history, :loss)...,label=\"loss\")\n",
    "plot(get(small_train_history, :loglikelihood)...,label=\"-loglikelihood\")\n",
    "plot(get(small_train_history, :KL)...,label=\"KL\")\n",
    "title(\"Training loss - smaller model\")\n",
    "xlabel(\"iteration\")\n",
    "ylabel(\"loss\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "plot(get(large_train_history, :loss)...,label=\"loss\")\n",
    "plot(get(large_train_history, :loglikelihood)...,label=\"-loglikelihood\")\n",
    "plot(get(large_train_history, :KL)...,label=\"KL\")\n",
    "title(\"Training loss - larger model\")\n",
    "xlabel(\"iteration\")\n",
    "ylabel(\"loss\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "pcolormesh(1:size(X,2), f, X)\n",
    "title(\"Original data\")\n",
    "xlabel(\"t\")\n",
    "ylabel(\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "sX = small_model(X).data\n",
    "pcolormesh(1:size(sX,2), f, sX)\n",
    "title(\"VAE output - smaller model\")\n",
    "xlabel(\"t\")\n",
    "ylabel(\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "lX = large_model(X).data\n",
    "pcolormesh(1:size(lX,2), f, lX)\n",
    "title(\"VAE output - larger model\")\n",
    "xlabel(\"t\")\n",
    "ylabel(\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training seems to work, now test the GPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to CuArrays\n",
    "zdim = 2\n",
    "cudata = data |> gpu\n",
    "cumodel = AlfvenDetectors.VAE([M, 200, zdim*2], [zdim, 200, M]) |> gpu\n",
    "cu_train_history = MVHistory()\n",
    "nepochs = 200\n",
    "L = 1\n",
    "β = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Training a large GPU model with less epochs in more iterations\"\n",
    "# clear cache\n",
    "\n",
    "@time AlfvenDetectors.fit!(cumodel, cudata, batchsize, 1;\n",
    "        L=L,β=β,\n",
    "        cbit = cbit, history = cu_train_history, verb = verb)\n",
    "    \n",
    "for i in 1:5\n",
    "    @time AlfvenDetectors.fit!(cumodel, cudata, batchsize, nepochs;\n",
    "        L=L,β=β,\n",
    "        cbit = cbit, history = cu_train_history, verb = verb)\n",
    "    # clear cache so that the gpu memory is cleared\n",
    "    GC.gc()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"large CPU model(data) timing\"\n",
    "@time large_model(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"GPU model(data) timing\"\n",
    "@time cumodel(cudata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of VAE, GPU is a considerable boost to training and evaluation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "plot(get(cu_train_history, :loss)...)\n",
    "title(\"GPU model training loss\")\n",
    "xlabel(\"iteration\")\n",
    "ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "X = cudata;\n",
    "_X = cumodel(X).data |> cpu\n",
    "pcolormesh(1:size(_X,2), f, _X)\n",
    "title(\"VAE output with GPU training\")\n",
    "xlabel(\"t\")\n",
    "ylabel(\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check further memory allocation for GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this part, lets try to see some sort of structure in the latent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save/load a pretrained model\n",
    "f = \"large_vae_model.bson\"\n",
    "if !isfile(f) \n",
    "    @save f large_model\n",
    "else\n",
    "    @load f large_model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, t1, f1 = get_msc_array(datapath, 11096, 11)\n",
    "pcolormesh(t1, f1, X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, t0, f0 = get_msc_array(datapath, 11096, 20)\n",
    "pcolormesh(t0, f0, X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xα = X1[:,1.06.<=t1.<=1.22]\n",
    "zα = large_model.encoder(Xα).data\n",
    "z1 = large_model.encoder(X1).data\n",
    "z0 = large_model.encoder(X0).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the code is not very N(0,1) since we have used a very low $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "scatter(z1[1,:], z1[2,:], label = \"positive\")\n",
    "scatter(z0[1,:], z0[2,:], label = \"negative\")\n",
    "scatter(zα[1,:], zα[2,:], label = \"alfven mode\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets \"generate\" a new diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function connect(zs, l)\n",
    "    L = length(zs)\n",
    "    return vcat([hcat(\n",
    "    collect(range(zs[i][1], zs[i+1][1]; length = l)), \n",
    "    collect(range(zs[i][2], zs[i+1][2]; length = l))\n",
    "        )\n",
    "    for i in 1:L-1]...)\n",
    "end\n",
    "zs = [[-1,-3.5], [0,-4.5], [1,-4.5], [2,-2], [0,0]]\n",
    "zpath = Array(connect(zs, 50)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "scatter(z1[1,:], z1[2,:], label = \"positive\")\n",
    "scatter(z0[1,:], z0[2,:], label = \"negative\")\n",
    "scatter(zα[1,:], zα[2,:], label = \"alfven mode\")\n",
    "plot(zpath[1,:], zpath[2,:], label = \"artificial z\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgen = large_model.decoder(zpath).data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "pcolormesh(Xgen)\n",
    "title(\"artificial coherence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also, lets try to sample from N(0,1) and give it to the decoder\n",
    "Xgen2 = AlfvenDetectors.sample(large_model, 100).data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a good results since only some strange phenomena were actually encoded to N(0,1), like the ends/beginnings of the shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "pcolormesh(Xgen2)\n",
    "title(\"generated artificial coherence\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also train a diag version of VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_model = AlfvenDetectors.VAE([M, 200, zdim*2], [zdim, 200, M*2],variant = :diag)\n",
    "diag_train_history = MVHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Training large CPU model with diagonal covariance\"\n",
    "\n",
    "# precompilation run\n",
    "@time AlfvenDetectors.fit!(diag_model, data, batchsize, 1;\n",
    "    L = L, β = 1.0,\n",
    "    cbit = cbit, history = diag_train_history, verb = verb)\n",
    "\n",
    "@time AlfvenDetectors.fit!(diag_model, data, batchsize, 100;\n",
    "    L = L, β = 1.0,\n",
    "    cbit = cbit, history = diag_train_history, verb = verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "plot(get(diag_train_history, :loss)..., label=\"loss\")\n",
    "plot(get(diag_train_history, :loglikelihood)..., label=\"-loglikelihood\")\n",
    "plot(get(diag_train_history, :KL)..., label=\"KL\")\n",
    "title(\"Training loss - large diagonal model\")\n",
    "xlabel(\"iteration\")\n",
    "ylabel(\"loss\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "dlX = diag_model(X).data\n",
    "pcolormesh(1:size(dlX,2), collect(1:M), dlX[1:M,:])\n",
    "title(\"VAE output - diagonal model (means)\")\n",
    "xlabel(\"t\")\n",
    "ylabel(\"f\")\n",
    "\n",
    "# before we ahve only taken the means, now sample from the posterior properly\n",
    "sdlX = AlfvenDetectors.samplenormal(dlX)\n",
    "figure()\n",
    "pcolormesh(1:size(sdlX,2), collect(1:M), sdlX)\n",
    "title(\"VAE output - diagonal model - samples of output\")\n",
    "xlabel(\"t\")\n",
    "ylabel(\"f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save/load a pretrained model\n",
    "f = \"diag_vae_model.bson\"\n",
    "if !isfile(f) \n",
    "    @save f diag_model\n",
    "else\n",
    "    @load f diag_model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, t1, f1 = get_msc_array(datapath, 11096, 11)\n",
    "pcolormesh(t1, f1, X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, t0, f0 = get_msc_array(datapath, 11096, 20)\n",
    "pcolormesh(t0, f0, X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xα = X1[:,1.06.<=t1.<=1.22]\n",
    "zα = diag_model.encoder(Xα).data\n",
    "z1 = diag_model.encoder(X1).data\n",
    "z0 = diag_model.encoder(X0).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code does not seem to be very N(0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "scatter(z1[1,:], z1[2,:], label = \"positive\")\n",
    "scatter(z0[1,:], z0[2,:], label = \"negative\")\n",
    "scatter(zα[1,:], zα[2,:], label = \"alfven mode\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "Obviously the sampling introduces noise in the places where we should see clear zeros but the structure is there. Also, artifacts are introduced in the output of the model with more training - overfitting? Also, tuning $\\beta$ does not play a role now as the output variance is estimated afterwards. Training is super slow. \n",
    "\n",
    "Tuning or not tuning of $\\beta$ does not seem to have an effect on the cluster in latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also train a diag version of VAE with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N = size(data)\n",
    "zdim = 2\n",
    "cudata = data |> gpu\n",
    "gpu_diag_model = AlfvenDetectors.VAE([M, 200, zdim*2], [zdim, 200, M*2],variant = :diag) |> gpu\n",
    "gpu_diag_train_history = MVHistory()\n",
    "L = 1\n",
    "verb = false\n",
    "cbit = 1\n",
    "batchsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Training large GPU model with diagonal covariance\"\n",
    "\n",
    "# precompilation run\n",
    "@time AlfvenDetectors.fit!(gpu_diag_model, cudata, batchsize, 1;\n",
    "    L = L, β = 0.01,\n",
    "    cbit = cbit, history = gpu_diag_train_history, verb = verb)\n",
    "\n",
    "@time AlfvenDetectors.fit!(gpu_diag_model, cudata, batchsize, 100;\n",
    "    L = L, β = 0.01,\n",
    "    cbit = cbit, history = gpu_diag_train_history, verb = verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here GPU is actually quite faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, lets try the scalar VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N = size(data)\n",
    "zdim = 2\n",
    "cudata = data |> gpu\n",
    "L = 1\n",
    "verb = false\n",
    "cbit = 1\n",
    "batchsize = 64\n",
    "\n",
    "scalar_model = AlfvenDetectors.VAE([M, 200, zdim*2], [zdim, 200, M+1],variant = :scalar) |> gpu\n",
    "scalar_train_history = MVHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Training large GPU model with scalar output variance\"\n",
    "\n",
    "# precompilation run\n",
    "@time AlfvenDetectors.fit!(scalar_model, cudata, batchsize, 1;\n",
    "    L = L, β = 1.0,\n",
    "    cbit = cbit, history = scalar_train_history, verb = verb)\n",
    "\n",
    "@time AlfvenDetectors.fit!(scalar_model, cudata, batchsize, 100;\n",
    "    L = L, β = 1.0,\n",
    "    cbit = cbit, history = scalar_train_history, verb = verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "plot(get(scalar_train_history, :loss)..., label=\"loss\")\n",
    "plot(get(scalar_train_history, :loglikelihood)..., label=\"-loglikelihood\")\n",
    "plot(get(scalar_train_history, :KL)..., label=\"KL\")\n",
    "title(\"Training loss - large diagonal model\")\n",
    "xlabel(\"iteration\")\n",
    "ylabel(\"loss\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "dlX = scalar_model(cudata).data |> cpu\n",
    "pcolormesh(1:size(dlX,2), collect(1:M), dlX[1:M,:])\n",
    "title(\"VAE output - diagonal model (means)\")\n",
    "xlabel(\"t\")\n",
    "ylabel(\"f\")\n",
    "\n",
    "# before we ahve only taken the means, now sample from the posterior properly\n",
    "sdlX = AlfvenDetectors.samplenormal_scalarvar(dlX)\n",
    "figure()\n",
    "pcolormesh(1:size(sdlX,2), collect(1:M), sdlX)\n",
    "title(\"VAE output - diagonal model - samples of output\")\n",
    "xlabel(\"t\")\n",
    "ylabel(\"f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save/load a pretrained model\n",
    "f = \"scalar_vae_model.bson\"\n",
    "if !isfile(f)\n",
    "    m = scalar_model |> cpu\n",
    "    @save f m\n",
    "else\n",
    "    @load f m\n",
    "    scalar_model = m |> gpu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, t1, f1 = get_msc_array(datapath, 11096, 11)\n",
    "pcolormesh(t1, f1, X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, t0, f0 = get_msc_array(datapath, 11096, 20)\n",
    "pcolormesh(t0, f0, X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X1 |> gpu\n",
    "X0 = X0 |> gpu\n",
    "Xα = X1[:,40:60]\n",
    "zα = scalar_model.encoder(Xα).data |> cpu\n",
    "z1 = scalar_model.encoder(X1).data |> cpu\n",
    "z0 = scalar_model.encoder(X0).data |> cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code does not seem to be very N(0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "scatter(z1[1,:], z1[2,:], label = \"positive\")\n",
    "scatter(z0[1,:], z0[2,:], label = \"negative\")\n",
    "scatter(zα[1,:], zα[2,:], label = \"alfven mode\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "Obviously the sampling introduces noise in the places where we should see clear zeros but the structure is there. Also, artifacts are introduced in the output of the model with more training - overfitting? Also, tuning $\\beta$ does not play a role now as the output variance is estimated afterwards. Training is super slow. \n",
    "\n",
    "Tuning or not tuning of $\\beta$ does not seem to have an effect on the cluster in latent space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
